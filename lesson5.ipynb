{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "PH_mcB21EoxE"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "bJQINrKnDqju"
   },
   "outputs": [],
   "source": [
    "with open('train_data.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    text = text.replace('\\ufeff', '') # убираем первый невидимый символ\n",
    "    text = re.sub(r'[^А-я ]', '', text) # убираем все недопустимые символы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "SubXLsi5ErEN",
    "outputId": "a1195ebc-bf1e-480e-a8c3-515036b53f09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Вы  лучший ответ на проблемы которые возникли в понедельникДумайте позитивно и верьте в свою способность достигать отличных результатовЕсли вы смогли в понедельник подняться с постели значит вы супер герой'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fyD7g4glKVps",
    "outputId": "abe937c1-231e-4616-c5fb-6c1fc6e2d77d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "IJD76YJ4E6z0"
   },
   "outputs": [],
   "source": [
    "num_characters = 34 #33 буквы + пробел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "DgiJrgsiIK_x"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "appv1wfpIJvH"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=num_characters, char_level=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "N1yoi7pGId-n"
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QJmXPaQbIf-I",
    "outputId": "06f4ad70-1f61-428d-e789-f876f3033f67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, 'о': 2, 'т': 3, 'е': 4, 'и': 5, 'в': 6, 'н': 7, 'с': 8, 'л': 9, 'п': 10, 'ь': 11, 'ы': 12, 'р': 13, 'а': 14, 'д': 15, 'у': 16, 'к': 17, 'з': 18, 'ч': 19, 'й': 20, 'м': 21, 'г': 22, 'б': 23, 'я': 24, 'ш': 25, 'ю': 26, 'х': 27}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "1wWs_206JRu-"
   },
   "outputs": [],
   "source": [
    "inp_chars = 3\n",
    "data = tokenizer.texts_to_matrix(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yqy7uBYCJTYV",
    "outputId": "f4f078a2-a14b-4d4e-ab1a-65029d4566e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HnWQb42jKAd1",
    "outputId": "f495a242-3799-4523-a0ce-22b76c56bba5"
   },
   "outputs": [],
   "source": [
    "n = data.shape[0]-inp_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "kvZ-iB9LKwgc"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "_nG7M5RIKsfs"
   },
   "outputs": [],
   "source": [
    "X = np.array([data[i:i+inp_chars, :] for i in range(n)])\n",
    "Y = data[inp_chars:] #предсказание следующего символа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z20DCMmSK3tj",
    "outputId": "8c4d6938-ea09-4058-f4a0-af19c3029b56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0NrELysIK5fL",
    "outputId": "7f4e2cf6-4fff-4078-c9bc-d9f5270154f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XbsyrcEGK7G7",
    "outputId": "523ea8a9-48a8-4da2-f2de-49f1a04cd246"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "lIP7yhRzLZsr"
   },
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gwyYcqGiLXPE",
    "outputId": "697cf7e3-d48a-4f60-f34c-55d188b3c914"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_13 (SimpleRNN)    (None, 1024)              1084416   \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 34)                34850     \n",
      "=================================================================\n",
      "Total params: 1,119,266\n",
      "Trainable params: 1,119,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input((inp_chars, num_characters)))\n",
    "model.add(SimpleRNN(1024, activation='tanh'))\n",
    "model.add(Dense(num_characters, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y3-y2cQiMGLK",
    "outputId": "380ed148-247e-46dc-f809-e98e4d62b1d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 3.3945 - accuracy: 0.0743\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 2.3960 - accuracy: 0.2970\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 2.0137 - accuracy: 0.3762\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 1.7476 - accuracy: 0.4356\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 1.6143 - accuracy: 0.4455\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 1.4429 - accuracy: 0.5198\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 1.3299 - accuracy: 0.5347\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 1.2782 - accuracy: 0.5594\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 1.2184 - accuracy: 0.6139\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 1.1856 - accuracy: 0.5594\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 1.1480 - accuracy: 0.5891\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 1.0581 - accuracy: 0.6139\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 1.0517 - accuracy: 0.6139\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 1.0621 - accuracy: 0.6238\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 1.0137 - accuracy: 0.6485\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 1.0204 - accuracy: 0.6386\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.9693 - accuracy: 0.6634\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.9440 - accuracy: 0.6683\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.9228 - accuracy: 0.6485\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.9063 - accuracy: 0.6832\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.8644 - accuracy: 0.6832\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.8730 - accuracy: 0.6584\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.8200 - accuracy: 0.7079\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.8357 - accuracy: 0.7228\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.8695 - accuracy: 0.6980\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.8471 - accuracy: 0.7030\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.8785 - accuracy: 0.7178\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.8572 - accuracy: 0.7426\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.8641 - accuracy: 0.7475\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.7881 - accuracy: 0.7574\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.7682 - accuracy: 0.7624\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.7553 - accuracy: 0.7673\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.7753 - accuracy: 0.7475\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.7404 - accuracy: 0.7574\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.7393 - accuracy: 0.7574\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.7577 - accuracy: 0.7723\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.7213 - accuracy: 0.7822\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.7116 - accuracy: 0.7723\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.7250 - accuracy: 0.7376\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.7330 - accuracy: 0.7525\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.8293 - accuracy: 0.7426\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.7474 - accuracy: 0.7475\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.7746 - accuracy: 0.7574\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.6838 - accuracy: 0.7723\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.7027 - accuracy: 0.7624\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.6632 - accuracy: 0.7723\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.6182 - accuracy: 0.8020\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.6382 - accuracy: 0.7921\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.7012 - accuracy: 0.7970\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.6318 - accuracy: 0.7970\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.5978 - accuracy: 0.8168\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.6108 - accuracy: 0.8119\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.6072 - accuracy: 0.8069\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.6002 - accuracy: 0.8168\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.6316 - accuracy: 0.7772\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.6398 - accuracy: 0.7871\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.6980 - accuracy: 0.7871\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.6561 - accuracy: 0.7525\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.6866 - accuracy: 0.7624\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.6488 - accuracy: 0.8119\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.6705 - accuracy: 0.7772\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.5817 - accuracy: 0.8069\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.6911 - accuracy: 0.7723\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.5151 - accuracy: 0.8218\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.6113 - accuracy: 0.8218\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.5456 - accuracy: 0.8267\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.5416 - accuracy: 0.8168\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.5204 - accuracy: 0.8317\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.5296 - accuracy: 0.8317\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.4987 - accuracy: 0.8366\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.6204 - accuracy: 0.7970\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.5389 - accuracy: 0.8218\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.4971 - accuracy: 0.8218\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.4843 - accuracy: 0.8366\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.4558 - accuracy: 0.8267\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.4555 - accuracy: 0.8317\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.4773 - accuracy: 0.8317\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.4873 - accuracy: 0.8564\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.4683 - accuracy: 0.8614\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.4825 - accuracy: 0.8317\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.4599 - accuracy: 0.8267\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.4708 - accuracy: 0.8416\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.4794 - accuracy: 0.8218\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.4438 - accuracy: 0.8614\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.4688 - accuracy: 0.8515\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.5146 - accuracy: 0.7970\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.5422 - accuracy: 0.8020\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.4886 - accuracy: 0.8267\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.5645 - accuracy: 0.8020\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.4703 - accuracy: 0.8515\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.4922 - accuracy: 0.8317\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.5158 - accuracy: 0.8317\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.5178 - accuracy: 0.7970\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.4850 - accuracy: 0.8317\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.4277 - accuracy: 0.8366\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.5017 - accuracy: 0.8713\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.4297 - accuracy: 0.8762\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.3833 - accuracy: 0.8614\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.4087 - accuracy: 0.8713\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.3959 - accuracy: 0.8515\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "history = model.fit(X, Y, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "s0_LNL2pMiku"
   },
   "outputs": [],
   "source": [
    "def buildPhrase(inp_str, str_len = 50):\n",
    "  for i in range(str_len):\n",
    "    x = []\n",
    "    for j in range(i, i+inp_chars):\n",
    "      x.append(tokenizer.texts_to_matrix(inp_str[j])) # преобразуем символы в One-Hot-encoding\n",
    " \n",
    "    x = np.array(x)\n",
    "    inp = x.reshape(1, inp_chars, num_characters)\n",
    " \n",
    "    pred = model.predict( inp ) # предсказываем OHE четвертого символа\n",
    "    d = tokenizer.index_word[pred.argmax(axis=1)[0]] # получаем ответ в символьном представлении\n",
    " \n",
    "    inp_str += d # дописываем строку\n",
    " \n",
    "  return inp_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7-vxdO-dMijp",
    "outputId": "d81ed2a6-53fd-4120-8297-706043ef0518"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "утреннрйе дте нсаво ио л вничыо иы л   учывуши льй ычио \n"
     ]
    }
   ],
   "source": [
    "res = buildPhrase(\"утренн\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Lp6XvkoOYyH"
   },
   "source": [
    "# Слова\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_-Wq8QJ2PDM2"
   },
   "outputs": [],
   "source": [
    "# Пример текста для обучения\n",
    "corpus = \"Вы — лучший ответ на проблемы, которые возникли в понедельник. Думайте позитивно и верьте в свою способность достигать отличных результатов. Если вы смогли в понедельник подняться с постели, значит вы супер герой.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "revghpcNPQSd"
   },
   "outputs": [],
   "source": [
    "# Преобразование входных данных\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([corpus])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "input_sequences = []\n",
    "for line in corpus.split('\\n'):\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "max_sequence_length = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HPga89Z4PVFe",
    "outputId": "057e9610-e34d-4c95-e931-b33aa6341ece"
   },
   "outputs": [],
   "source": [
    "# Создание признаков и меток\n",
    "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7mpCwwYQP5hV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.3327 - accuracy: 0.0323\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.3301 - accuracy: 0.0645\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.3274 - accuracy: 0.0968\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.3244 - accuracy: 0.0968\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3209 - accuracy: 0.0968\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.3166 - accuracy: 0.0968\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.3111 - accuracy: 0.0968\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.3037 - accuracy: 0.0968\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.2932 - accuracy: 0.0968\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2781 - accuracy: 0.0968\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2585 - accuracy: 0.0968\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2495 - accuracy: 0.0968\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2403 - accuracy: 0.0968\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2172 - accuracy: 0.0968\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2078 - accuracy: 0.0968\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.1970 - accuracy: 0.0968\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.1663 - accuracy: 0.0968\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1183 - accuracy: 0.0968\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1081 - accuracy: 0.0968\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.0338 - accuracy: 0.1613\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.0028 - accuracy: 0.0968\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9371 - accuracy: 0.0968\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.9374 - accuracy: 0.0968\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 2.8394 - accuracy: 0.1613\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8788 - accuracy: 0.1290\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9164 - accuracy: 0.0645\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.8911 - accuracy: 0.0645\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.7353 - accuracy: 0.1613\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9261 - accuracy: 0.1290\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.7103 - accuracy: 0.1613\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 2.7841 - accuracy: 0.0645\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.7939 - accuracy: 0.0645\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7271 - accuracy: 0.0968\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.6726 - accuracy: 0.1613\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.6916 - accuracy: 0.1290\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7051 - accuracy: 0.1290\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.6533 - accuracy: 0.1290\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.6028 - accuracy: 0.1290\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.6076 - accuracy: 0.1290\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6102 - accuracy: 0.1613\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.5570 - accuracy: 0.0968\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.5130 - accuracy: 0.0968\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5274 - accuracy: 0.0968\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.4675 - accuracy: 0.0968\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.4335 - accuracy: 0.0968\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4319 - accuracy: 0.1290\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.3587 - accuracy: 0.2258\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.3685 - accuracy: 0.1613\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2986 - accuracy: 0.2581\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3105 - accuracy: 0.2581\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 2.2388 - accuracy: 0.1613\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2580 - accuracy: 0.2903\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.1876 - accuracy: 0.2581\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.1655 - accuracy: 0.2581\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.1766 - accuracy: 0.2903\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1112 - accuracy: 0.2581\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.0541 - accuracy: 0.3548\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 2.0656 - accuracy: 0.3226\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1072 - accuracy: 0.2903\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0529 - accuracy: 0.2903\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.9693 - accuracy: 0.3548\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9160 - accuracy: 0.4839\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9014 - accuracy: 0.4516\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9455 - accuracy: 0.3548\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0296 - accuracy: 0.2581\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0868 - accuracy: 0.2581\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8484 - accuracy: 0.4839\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.1896 - accuracy: 0.1613\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8658 - accuracy: 0.4194\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.9533 - accuracy: 0.2903\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8112 - accuracy: 0.3548\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8755 - accuracy: 0.2258\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.7781 - accuracy: 0.5484\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8185 - accuracy: 0.4194\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7451 - accuracy: 0.6129\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8040 - accuracy: 0.2581\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7104 - accuracy: 0.6452\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7361 - accuracy: 0.5484\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6903 - accuracy: 0.6129\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6675 - accuracy: 0.4839\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6598 - accuracy: 0.5806\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6488 - accuracy: 0.4839\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 998us/step - loss: 1.5973 - accuracy: 0.6774\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6200 - accuracy: 0.4839\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5638 - accuracy: 0.6129\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.5748 - accuracy: 0.5484\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.5360 - accuracy: 0.5806\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.5207 - accuracy: 0.6129\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5393 - accuracy: 0.4839\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5036 - accuracy: 0.6129\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.4731 - accuracy: 0.6129\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.4515 - accuracy: 0.6129\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.4304 - accuracy: 0.6129\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4394 - accuracy: 0.6774\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5554 - accuracy: 0.5161\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9386 - accuracy: 0.3226\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5818 - accuracy: 0.5161\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9113 - accuracy: 0.2258\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4908 - accuracy: 0.4516\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8142 - accuracy: 0.1290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1df7bfbbfd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Определение модели нейронной сети\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 10, input_length=max_sequence_length-1))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(predictors, label, epochs=100, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ILtfEKKIQH2d",
    "outputId": "b7bb8b2d-0a3f-40ba-bc24-3ff502ef458a"
   },
   "outputs": [],
   "source": [
    "# Функция для генерации текста\n",
    "def generate_text(seed_text, next_words, model, max_sequence_length, tokenizer):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "        \n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pVSmTo2qQyer"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Утренний позитив добавляет годы ответ ответ ответ ответ ответ ответ проблемы проблемы проблемы думайте\n"
     ]
    }
   ],
   "source": [
    "# Генерация текста\n",
    "seed_text = \"Утренний позитив добавляет годы\"\n",
    "generated_text = generate_text(seed_text, 10, model, max_sequence_length, tokenizer)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
